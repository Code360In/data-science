{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an Azure Machine Learning Pipeline\n",
    "\n",
    "You can perform the various steps required to ingest data, train a model, and register the model individually by using the Azure ML SDK to run script-based experiments. However, in an enterprise environment it is common to encapsulate the sequence of discrete steps required to build a machine learning solution into a *pipeline* that can be run on one or more compute targets, either on-demand by a user, from an automated build process, or on a schedule.\n",
    "\n",
    "In this lab, you'll bring together all of these elements to create a simple pipeline that trains and registers a model.\n",
    "\n",
    "## Connect to Your Workspace\n",
    "\n",
    "The first thing you need to do is to connect to your workspace using the Azure ML SDK.\n",
    "\n",
    "> **Note**: If the authenticated session with your Azure subscription has expired since you completed the previous exercise, you'll be prompted to reauthenticate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code FPCBK5RTK to authenticate.\n",
      "Interactive authentication successfully completed.\n",
      "Ready to use Azure ML 1.6.0 to work with wfml\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Training Data\n",
    "\n",
    "You can use local data files to train a model, but when running training workloads automatically on cloud-based compute, it makes more sense to store the data centrally in the cloud and ingest it into the training script wherever it happens to be running.\n",
    "\n",
    "In this lab, you'll upload the training data to a *datastore* and define a *dataset* that can be used to access the data from a training script. For simplicity, you'll upload the data to the default datastore for your Azure Machine Learning workspace - this is an Azure Storage blob container that was created when you provisioned the workspace. In a real solution, you'd likely register a datastore that references the cloud location where you typically store your data. You'll then create a *tabular* dataset that references the CSV files you uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Uploading ./data/diabetes.csv\n",
      "Uploading ./data/diabetes2.csv\n",
      "Uploaded ./data/diabetes2.csv, 1 files out of an estimated total of 2\n",
      "Uploaded ./data/diabetes.csv, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n",
      "Dataset registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'diabetes dataset' not in ws.datasets:\n",
    "    default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
    "                        target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "\n",
    "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "    # Register the tabular dataset\n",
    "    try:\n",
    "        tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                name='diabetes dataset',\n",
    "                                description='diabetes data',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Scripts for Pipeline Steps\n",
    "\n",
    "Now you're ready to start work on your pipeline. Pipelines consist of one or more *steps*, which can be Python scripts, or specialized steps like an Auto ML training estimator or a data transfer step that copies data from one location to another. Each step can run in its own compute context.\n",
    "\n",
    "In this exercise, you'll build a simple pipeline that contains an estimator step (to train a model) and a Python script step (to register the trained model). Start by creating a folder to contain the scripts for each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = 'diabetes_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step will use an estimator to run a training script. The code in the following cell creates this script for you. Note that the script includes a parameter named **output_folder**, which references the folder where the trained model should be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_pipeline/train_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/train_diabetes.py\n",
    "# Import libraries\n",
    "from azureml.core import Run\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_folder', type=str, dest='output_folder', default=\"diabetes_model\", help='output folder')\n",
    "args = parser.parse_args()\n",
    "output_folder = args.output_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "diabetes = run.input_datasets['diabetes_train'].to_pandas_dataframe()\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train adecision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = output_folder + \"/model.pkl\"\n",
    "joblib.dump(value=model, filename=output_path)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script for the second step of the pipeline will load the model from where it was saved, and then register it in the workspace. It includes a single **model_folder** parameter that contains the path to the folder where the model was saved by the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_pipeline/register_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/register_diabetes.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "import joblib\n",
    "from azureml.core import Workspace, Model, Run\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_folder', type=str, dest='model_folder', default=\"diabetes_model\", help='model location')\n",
    "args = parser.parse_args()\n",
    "model_folder = args.model_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the model\n",
    "print(\"Loading model from \" + model_folder)\n",
    "model_file = model_folder + \"/model.pkl\"\n",
    "model = joblib.load(model_file)\n",
    "\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path = model_file,\n",
    "               model_name = 'diabetes_model',\n",
    "               tags={'Training context':'Pipeline'})\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a Compute Environment for the Pipeline Steps\n",
    "\n",
    "The pipeline will eventually be published and run on-demand, so it needs a compute environment in which to run. In this exercise, you'll use the same compute for both steps, but it's important to realize that each step is run independently; so you could specify different compute contexts for each step if appropriate.\n",
    "\n",
    "First, you need a compute target. In this case, you create an Azure Machine Learning compute cluster in your workspace (or use an existing one if you have created it previously).\n",
    "\n",
    "> **Important**: Change *your-compute-cluster* to the unique name for your compute cluster in the code below before running it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"wfml-cluster\"\n",
    "\n",
    "# Verify that cluster exists\n",
    "try:\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If not, create it\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                           max_nodes=4,\n",
    "                                                           idle_seconds_before_scaledown=1800)\n",
    "    pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "pipeline_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compute will require a Python environment with the necessary package dependencies installed, so we'll create a run configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "diabetes_env = Environment(\"diabetes-pipeline-env\")\n",
    "diabetes_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "diabetes_env.docker.enabled = True # Use a docker container\n",
    "\n",
    "# Create a set of package dependencies\n",
    "diabetes_packages = CondaDependencies.create(conda_packages=['scikit-learn','pandas'],\n",
    "                                             pip_packages=['azureml-sdk'])\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "diabetes_env.python.conda_dependencies = diabetes_packages\n",
    "\n",
    "# Register the environment (just in case you want to use it again)\n",
    "diabetes_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'diabetes-pipeline-env')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Run a Pipeline\n",
    "\n",
    "Now you're ready to define and run the pipeline.\n",
    "\n",
    "First you need to define the steps for the pipeline, and any data references that need to passed between them. In this case, the first step must write the model to a folder that can be read from by the second step. Since the steps will be run on remote compute (and in fact, could each be run on different compute), the folder path must be passed as a data reference to a location in a datastore within the workspace. The **PipelineData** object is a special kind of data reference that is used to pass data from the output of one pipeline step to the input of another, creating a dependency between them. You'll create one and use it as the output for the first step and the input for the second step. Note that you also need to pass it as a script argument so your code can access the datastore location referenced by the data reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Create a PipelineData (temporary Data Reference) for the model folder\n",
    "model_folder = PipelineData(\"model_folder\", datastore=ws.get_default_datastore())\n",
    "\n",
    "estimator = Estimator(source_directory=experiment_folder,\n",
    "                        compute_target = pipeline_cluster,\n",
    "                        environment_definition=pipeline_run_config.environment,\n",
    "                        entry_script='train_diabetes.py')\n",
    "\n",
    "# Step 1, run the estimator to train the model\n",
    "train_step = EstimatorStep(name = \"Train Model\",\n",
    "                           estimator=estimator, \n",
    "                           estimator_entry_script_arguments=['--output_folder', model_folder],\n",
    "                           inputs=[diabetes_ds.as_named_input('diabetes_train')],\n",
    "                           outputs=[model_folder],\n",
    "                           compute_target = pipeline_cluster,\n",
    "                           allow_reuse = True)\n",
    "\n",
    "# Step 2, run the model registration script\n",
    "register_step = PythonScriptStep(name = \"Register Model\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"register_diabetes.py\",\n",
    "                                arguments = ['--model_folder', model_folder],\n",
    "                                inputs=[model_folder],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now you're ready to build the pipeline from the steps you've defined and run it as an experiment.\n",
    "\n",
    "> **Note**: This may take a while. The training cluster must be started and configured with the Python environment before the scripts can be run. Now might be a good time to take a coffee break!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n",
      "Created step Train Model [3786d22e][c62f9f98-43df-4188-9bf4-33d619a42546], (This step will run and generate new outputs)\n",
      "Created step Register Model [46a89ba4][d2b46840-f147-484b-993d-a1d5e736abf5], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun ba5f74e1-b67f-4ff6-b063-059d3c605853\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/ba5f74e1-b67f-4ff6-b063-059d3c605853?wsid=/subscriptions/4e5d3b1b-eba9-4974-b060-30a0ce055e02/resourcegroups/learn-4b2f634a-7e30-4f6d-b89c-3217df1e9c0f/workspaces/wfml\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db02c1027583452bb0e61dd2b25c027a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"loading\": true}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: ba5f74e1-b67f-4ff6-b063-059d3c605853\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/ba5f74e1-b67f-4ff6-b063-059d3c605853?wsid=/subscriptions/4e5d3b1b-eba9-4974-b060-30a0ce055e02/resourcegroups/learn-4b2f634a-7e30-4f6d-b89c-3217df1e9c0f/workspaces/wfml\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: d9fe4a7a-5431-4a16-bc22-4536be69f64f\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/d9fe4a7a-5431-4a16-bc22-4536be69f64f?wsid=/subscriptions/4e5d3b1b-eba9-4974-b060-30a0ce055e02/resourcegroups/learn-4b2f634a-7e30-4f6d-b89c-3217df1e9c0f/workspaces/wfml\n",
      "StepRun( Train Model ) Status: NotStarted\n",
      "StepRun( Train Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2020/06/06 19:24:28 Downloading source code...\n",
      "2020/06/06 19:24:29 Finished downloading source code\n",
      "2020/06/06 19:24:30 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2020/06/06 19:24:30 Successfully set up Docker network: acb_default_network\n",
      "2020/06/06 19:24:30 Setting up Docker configuration...\n",
      "2020/06/06 19:24:31 Successfully set up Docker configuration\n",
      "2020/06/06 19:24:31 Logging in to registry: wfml021f814e.azurecr.io\n",
      "2020/06/06 19:24:32 Successfully logged into wfml021f814e.azurecr.io\n",
      "2020/06/06 19:24:32 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/06/06 19:24:32 Scanning for dependencies...\n",
      "2020/06/06 19:24:33 Successfully scanned dependencies\n",
      "2020/06/06 19:24:33 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  60.93kB\n",
      "\n",
      "Step 1/15 : FROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05: Pulling from azureml/base\n",
      "Digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      " ---> 93a72e6bd1ce\n",
      "Step 2/15 : USER root\n",
      " ---> Running in 0649cbd7a753\n",
      "Removing intermediate container 0649cbd7a753\n",
      " ---> 36bf22c60a16\n",
      "Step 3/15 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in cdeab79ede47\n",
      "Removing intermediate container cdeab79ede47\n",
      " ---> ea8dcc9120fb\n",
      "Step 4/15 : WORKDIR /\n",
      " ---> Running in e8d8aefafeb4\n",
      "Removing intermediate container e8d8aefafeb4\n",
      " ---> fc122542908d\n",
      "Step 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> f849dcb5681a\n",
      "Step 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in be3c2d042d93\n",
      "Removing intermediate container be3c2d042d93\n",
      " ---> 46052784417c\n",
      "Step 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> bf10a10d0db0\n",
      "Step 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_7b128fbfa600b67b9d3fa44f93754ed3 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 212a90f4ea25\n",
      "Solving environment: ...working... \n",
      "done\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "libedit-3.1          | 171 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | #######6   |  76% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | #########3 |  94% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "joblib-0.15.1        | 207 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "joblib-0.15.1        | 207 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "numpy-base-1.18.1    | 5.2 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "numpy-base-1.18.1    | 5.2 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "numpy-base-1.18.1    | 5.2 MB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "numpy-base-1.18.1    | 5.2 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "scipy-1.4.1          | 18.9 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | ##8        |  29% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | #########5 |  95% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libffi-3.2.1         | 43 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "libffi-3.2.1         | 43 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | ########1  |  81% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ca-certificates-2020 | 132 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ca-certificates-2020 | 132 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "wheel-0.34.2         | 49 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "wheel-0.34.2         | 49 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 387 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | #######9   |  79% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | #########4 |  95% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | #######6   |  77% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | #########9 |  99% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python-dateutil-2.8. | 224 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "python-dateutil-2.8. | 224 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "setuptools-47.1.1    | 653 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "setuptools-47.1.1    | 653 KB    | ########7  |  88% \u001b[0m\u001b[91m\n",
      "setuptools-47.1.1    | 653 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl_fft-1.0.15       | 173 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "mkl_fft-1.0.15       | 173 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl_random-1.1.0     | 369 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "mkl_random-1.1.0     | 369 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "six-1.14.0           | 27 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "six-1.14.0           | 27 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ##         |  21% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ####3      |  44% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ######7    |  67% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########2  |  82% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #########3 |  93% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pip-20.0.2           | 1.9 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "pip-20.0.2           | 1.9 MB    | #######8   |  78% \u001b[0m\u001b[91m\n",
      "pip-20.0.2           | 1.9 MB    | #########6 |  96% \u001b[0m\u001b[91m\n",
      "pip-20.0.2           | 1.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "numpy-1.18.1         | 5 KB      |            |   0% \u001b[0m\u001b[91m\n",
      "numpy-1.18.1         | 5 KB      | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | #######7   |  78% \u001b[0m\u001b[91m\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "scikit-learn-0.22.1  | 7.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.22.1  | 7.1 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.22.1  | 7.1 MB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.22.1  | 7.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl-2019.4           | 204.1 MB  |            |   0% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | 3          |   3% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | 7          |   8% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #2         |  13% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #8         |  18% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ##3        |  23% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ##8        |  28% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ###2       |  33% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ###6       |  37% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ####1      |  41% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ####6      |  46% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #####1     |  51% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #####6     |  56% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ######1    |  61% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ######6    |  66% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #######1   |  71% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #######5   |  76% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #######9   |  79% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########1  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########3  |  84% \u001b[0m\n",
      "\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\n",
      "\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\n",
      "\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "intel-openmp-2020.1  | 940 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "intel-openmp-2020.1  | 940 KB    | ########8  |  88% \u001b[0m\u001b[91m\n",
      "intel-openmp-2020.1  | 940 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "tk-8.6.8             | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #######6   |  77% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #########  |  90% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pandas-1.0.3         | 11.1 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "pandas-1.0.3         | 11.1 MB   | ####       |  40% \u001b[0m\u001b[91m\n",
      "pandas-1.0.3         | 11.1 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "pandas-1.0.3         | 11.1 MB   | #########2 |  92% \u001b[0m\u001b[91m\n",
      "pandas-1.0.3         | 11.1 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "blas-1.0             | 6 KB      |            |   0% \u001b[0m\u001b[91m\n",
      "blas-1.0             | 6 KB      | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pytz-2020.1          | 239 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "pytz-2020.1          | 239 KB    | #########3 |  93% \u001b[0m\u001b[91m\n",
      "pytz-2020.1          | 239 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl-service-2.3.0    | 208 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "mkl-service-2.3.0    | 208 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "certifi-2020.4.5.1   | 159 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "certifi-2020.4.5.1   | 159 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "xz-5.2.5             | 438 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "xz-5.2.5             | 438 KB    | #########8 |  99% \u001b[0m\u001b[91m\n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \u001b[0m\n",
      "Downloading and Extracting Packages\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting azureml-sdk~=1.6.0\n",
      "  Downloading azureml_sdk-1.6.0-py3-none-any.whl (4.6 kB)\n",
      "Collecting azureml-train~=1.6.0\n",
      "  Downloading azureml_train-1.6.0-py3-none-any.whl (3.2 kB)\n",
      "Collecting azureml-pipeline~=1.6.0\n",
      "  Downloading azureml_pipeline-1.6.0-py3-none-any.whl (3.7 kB)\n",
      "Collecting azureml-train-automl-client~=1.6.0\n",
      "  Downloading azureml_train_automl_client-1.6.0.post1-py3-none-any.whl (88 kB)\n",
      "Collecting azureml-core~=1.6.0\n",
      "  Downloading azureml_core-1.6.0.post1-py3-none-any.whl (1.3 MB)\n",
      "Collecting azureml-dataprep[fuse]<1.7.0a,>=1.6.2a\n",
      "  Downloading azureml_dataprep-1.6.3-py3-none-any.whl (27.8 MB)\n",
      "Collecting azureml-train-core~=1.6.0\n",
      "  Downloading azureml_train_core-1.6.0.post1-py3-none-any.whl (8.6 MB)\n",
      "Collecting azureml-pipeline-core~=1.6.0\n",
      "  Downloading azureml_pipeline_core-1.6.0-py3-none-any.whl (290 kB)\n",
      "Collecting azureml-pipeline-steps~=1.6.0\n",
      "  Downloading azureml_pipeline_steps-1.6.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: pytz in /azureml-envs/azureml_7b128fbfa600b67b9d3fa44f93754ed3/lib/python3.6/site-packages (from azureml-train-automl-client~=1.6.0->azureml-sdk~=1.6.0->-r /azureml-environment-setup/condaenv.cl5tdz37.requirements.txt (line 1)) (2020.1)\n",
      "Collecting azureml-automl-core~=1.6.0\n",
      "  Downloading azureml_automl_core-1.6.0-py3-none-any.whl (124 kB)\n",
      "Collecting azureml-telemetry~=1.6.0\n",
      "  Downloading azureml_telemetry-1.6.0-py3-none-any.whl (29 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.25.9-py2.py3-none-any.whl (126 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting msrest>=0.5.1\n",
      "  Downloading msrest-0.6.15-py2.py3-none-any.whl (84 kB)\n",
      "Collecting pyopenssl\n",
      "  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting SecretStorage\n",
      "  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.3-py2.py3-none-any.whl (40 kB)\n",
      "Collecting requests>=2.19.1\n",
      "  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting azure-mgmt-storage>=1.5.0\n",
      "  Downloading azure_mgmt_storage-10.0.0-py2.py3-none-any.whl (532 kB)\n",
      "Collecting azure-mgmt-keyvault>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /azureml-envs/azureml_7b128fbfa600b67b9d3fa44f93754ed3/lib/python3.6/site-packages (from azureml-core~=1.6.0->azureml-sdk~=1.6.0->-r /azureml-environment-setup/condaenv.cl5tdz37.requirements.txt (line 1)) (2.8.1)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting azure-mgmt-resource>=1.2.1\n",
      "  Downloading azure_mgmt_resource-10.0.0-py2.py3-none-any.whl (809 kB)\n",
      "Collecting adal>=1.2.0\n",
      "  Downloading adal-1.2.4-py2.py3-none-any.whl (55 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n",
      "  Downloading cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7 MB)\n",
      "Collecting docker\n",
      "  Downloading docker-4.2.1-py2.py3-none-any.whl (143 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting PyJWT\n",
      "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting azure-mgmt-network~=10.0\n",
      "  Downloading azure_mgmt_network-10.2.0-py2.py3-none-any.whl (8.6 MB)\n",
      "Collecting ruamel.yaml>0.16.7\n",
      "  Downloading ruamel.yaml-0.16.10-py2.py3-none-any.whl (111 kB)\n",
      "Collecting azure-common>=1.1.12\n",
      "  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\n",
      "Collecting pathspec\n",
      "  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting azure-mgmt-authorization>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.60.0-py2.py3-none-any.whl (82 kB)\n",
      "Collecting azure-graphrbac>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting azure-identity<1.3.0,>=1.2.0\n",
      "  Downloading azure_identity-1.2.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting azureml-dataprep-native<15.0.0,>=14.1.0\n",
      "  Downloading azureml_dataprep_native-14.2.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting dotnetcore2>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.14-py3-none-manylinux1_x86_64.whl (29.3 MB)\n",
      "Collecting cloudpickle>=1.1.0\n",
      "  Downloading cloudpickle-1.4.1-py3-none-any.whl (26 kB)\n",
      "Collecting fusepy>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting flake8<=3.7.9,>=3.1.0; python_version >= \"3.6\"\n",
      "  Downloading flake8-3.7.9-py2.py3-none-any.whl (69 kB)\n",
      "Collecting azureml-train-restclients-hyperdrive~=1.6.0\n",
      "  Downloading azureml_train_restclients_hyperdrive-1.6.0-py3-none-any.whl (18 kB)\n",
      "Collecting applicationinsights\n",
      "  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-1.6.1-py2.py3-none-any.whl (31 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_7b128fbfa600b67b9d3fa44f93754ed3/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core~=1.6.0->azureml-sdk~=1.6.0->-r /azureml-environment-setup/condaenv.cl5tdz37.requirements.txt (line 1)) (2020.4.5.1)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: six>=1.5.2 in /azureml-envs/azureml_7b128fbfa600b67b9d3fa44f93754ed3/lib/python3.6/site-packages (from pyopenssl->azureml-core~=1.6.0->azureml-sdk~=1.6.0->-r /azureml-environment-setup/condaenv.cl5tdz37.requirements.txt (line 1)) (1.14.0)\n",
      "Collecting jeepney>=0.4.2\n",
      "  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (399 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n",
      "  Downloading ruamel.yaml.clib-0.2.0-cp36-cp36m-manylinux1_x86_64.whl (548 kB)\n",
      "Collecting msal-extensions~=0.1.3\n",
      "  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting msal<2.0.0,>=1.0.0\n",
      "  Downloading msal-1.3.0-py2.py3-none-any.whl (48 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.6.0-py2.py3-none-any.whl (120 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting pyflakes<2.2.0,>=2.1.0\n",
      "  Downloading pyflakes-2.1.1-py2.py3-none-any.whl (59 kB)\n",
      "Collecting pycodestyle<2.6.0,>=2.5.0\n",
      "  Downloading pycodestyle-2.5.0-py2.py3-none-any.whl (51 kB)\n",
      "Collecting mccabe<0.7.0,>=0.6.0\n",
      "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Collecting entrypoints<0.4.0,>=0.3.0\n",
      "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting portalocker~=1.0\n",
      "  Downloading portalocker-1.7.0-py2.py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: fusepy\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=2cdecb80104bd8ebf3964146c3bfb13ebfd66f89af5d718825f66769b98052bf\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "Successfully built fusepy\n",
      "Installing collected packages: urllib3, pycparser, cffi, cryptography, pyopenssl, pyasn1, ndg-httpsclient, zipp, importlib-metadata, jsonpickle, contextlib2, isodate, chardet, idna, requests, oauthlib, requests-oauthlib, msrest, jeepney, SecretStorage, PyJWT, adal, msrestazure, azure-common, azure-mgmt-storage, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-resource, websocket-client, docker, backports.weakref, backports.tempfile, azure-mgmt-network, ruamel.yaml.clib, ruamel.yaml, pathspec, jmespath, azure-mgmt-authorization, azure-graphrbac, azureml-core, pyflakes, pycodestyle, mccabe, entrypoints, flake8, applicationinsights, azureml-telemetry, azureml-train-restclients-hyperdrive, azureml-train-core, azureml-train, azureml-pipeline-core, portalocker, msal, msal-extensions, azure-core, azure-identity, azureml-dataprep-native, distro, dotnetcore2, cloudpickle, fusepy, azureml-dataprep, azureml-automl-core, azureml-train-automl-client, azureml-pipeline-steps, azureml-pipeline, azureml-sdk\n",
      "\n",
      "Successfully installed PyJWT-1.7.1 SecretStorage-3.1.2 adal-1.2.4 applicationinsights-0.11.9 azure-common-1.1.25 azure-core-1.6.0 azure-graphrbac-0.61.1 azure-identity-1.2.0 azure-mgmt-authorization-0.60.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-network-10.2.0 azure-mgmt-resource-10.0.0 azure-mgmt-storage-10.0.0 azureml-automl-core-1.6.0 azureml-core-1.6.0.post1 azureml-dataprep-1.6.3 azureml-dataprep-native-14.2.0 azureml-pipeline-1.6.0 azureml-pipeline-core-1.6.0 azureml-pipeline-steps-1.6.0 azureml-sdk-1.6.0 azureml-telemetry-1.6.0 azureml-train-1.6.0 azureml-train-automl-client-1.6.0.post1 azureml-train-core-1.6.0.post1 azureml-train-restclients-hyperdrive-1.6.0 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.0 chardet-3.0.4 cloudpickle-1.4.1 contextlib2-0.6.0.post1 cryptography-2.9.2 distro-1.5.0 docker-4.2.1 dotnetcore2-2.1.14 entrypoints-0.3 flake8-3.7.9 fusepy-3.0.1 idna-2.9 importlib-metadata-1.6.1 isodate-0.6.0 jeepney-0.4.3 jmespath-0.10.0 jsonpickle-1.4.1 mccabe-0.6.1 msal-1.3.0 msal-extensions-0.1.3 msrest-0.6.15 msrestazure-0.6.3 ndg-httpsclient-0.5.1 oauthlib-3.1.0 pathspec-0.8.0 portalocker-1.7.0 pyasn1-0.4.8 pycodestyle-2.5.0 pycparser-2.20 pyflakes-2.1.1 pyopenssl-19.1.0 requests-2.23.0 requests-oauthlib-1.3.0 ruamel.yaml-0.16.10 ruamel.yaml.clib-0.2.0 urllib3-1.25.9 websocket-client-0.57.0 zipp-3.1.0\n",
      "\u001b[91m\n",
      "\u001b[0m#\n",
      "# To activate this environment, use:\n",
      "# > source activate /azureml-envs/azureml_7b128fbfa600b67b9d3fa44f93754ed3\n",
      "#\n",
      "# To deactivate an active environment, use:\n",
      "# > source deactivate\n",
      "#\n",
      "\n",
      "\n",
      "Removing intermediate container 212a90f4ea25\n",
      " ---> 1c950cca8c99\n",
      "Step 9/15 : ENV PATH /azureml-envs/azureml_7b128fbfa600b67b9d3fa44f93754ed3/bin:$PATH\n",
      " ---> Running in 0da43c8a967c\n",
      "Removing intermediate container 0da43c8a967c\n",
      " ---> ea6b2de29958\n",
      "Step 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_7b128fbfa600b67b9d3fa44f93754ed3\n",
      " ---> Running in 5520d0ce0eaa\n",
      "Removing intermediate container 5520d0ce0eaa\n",
      " ---> 299d4b384a9a\n",
      "Step 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_7b128fbfa600b67b9d3fa44f93754ed3/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 5ae6fad65c03\n",
      "Removing intermediate container 5ae6fad65c03\n",
      " ---> e2b3d34e8b87\n",
      "Step 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 8e7d362f0285\n",
      "Step 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit \"--repositories\" \"[]\" /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in e075d530918a\n",
      "Removing intermediate container e075d530918a\n",
      " ---> 12aee9f709cd\n",
      "Step 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 6602a6a55425\n",
      "Removing intermediate container 6602a6a55425\n",
      " ---> 3a48ed0245b1\n",
      "Step 15/15 : CMD [\"bash\"]\n",
      " ---> Running in b624ab3933a1\n",
      "Removing intermediate container b624ab3933a1\n",
      " ---> b3e7a7e2615f\n",
      "Successfully built b3e7a7e2615f\n",
      "Successfully tagged wfml021f814e.azurecr.io/azureml/azureml_9bd7915d3e8a44ee288f6db64640f456:latest\n",
      "2020/06/06 19:27:52 Successfully executed container: acb_step_0\n",
      "2020/06/06 19:27:52 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/06/06 19:27:52 Pushing image: wfml021f814e.azurecr.io/azureml/azureml_9bd7915d3e8a44ee288f6db64640f456:latest, attempt 1\n",
      "The push refers to repository [wfml021f814e.azurecr.io/azureml/azureml_9bd7915d3e8a44ee288f6db64640f456]\n",
      "8f5107a2a04d: Preparing\n",
      "eb5126f5d16a: Preparing\n",
      "e75d0bbb7be2: Preparing\n",
      "e8c30f8d6b19: Preparing\n",
      "e9146fafec7e: Preparing\n",
      "fa49e180eb62: Preparing\n",
      "e1171d4d60ca: Preparing\n",
      "6ef1a8ae63b7: Preparing\n",
      "85389f9ead9e: Preparing\n",
      "f2608f66a0e3: Preparing\n",
      "0e259b09e5f4: Preparing\n",
      "340dc32eb998: Preparing\n",
      "df18b66efaa6: Preparing\n",
      "ccdb13a20bf2: Preparing\n",
      "9513cdf4e497: Preparing\n",
      "7f083f9454c0: Preparing\n",
      "29f36b5893dc: Preparing\n",
      "f2608f66a0e3: Waiting\n",
      "0e259b09e5f4: Waiting\n",
      "340dc32eb998: Waiting\n",
      "df18b66efaa6: Waiting\n",
      "ccdb13a20bf2: Waiting\n",
      "9513cdf4e497: Waiting\n",
      "7f083f9454c0: Waiting\n",
      "29f36b5893dc: Waiting\n",
      "fa49e180eb62: Waiting\n",
      "e1171d4d60ca: Waiting\n",
      "6ef1a8ae63b7: Waiting\n",
      "85389f9ead9e: Waiting\n",
      "8f5107a2a04d: Pushed\n",
      "e75d0bbb7be2: Pushed\n",
      "e9146fafec7e: Pushed\n",
      "e8c30f8d6b19: Pushed\n",
      "fa49e180eb62: Pushed\n",
      "e1171d4d60ca: Pushed\n",
      "6ef1a8ae63b7: Pushed\n",
      "340dc32eb998: Pushed\n",
      "85389f9ead9e: Pushed\n",
      "ccdb13a20bf2: Pushed\n",
      "0e259b09e5f4: Pushed\n",
      "9513cdf4e497: Pushed\n",
      "7f083f9454c0: Pushed\n",
      "f2608f66a0e3: Pushed\n",
      "df18b66efaa6: Pushed\n",
      "29f36b5893dc: Pushed\n",
      "\n",
      "eb5126f5d16a: Pushed\n",
      "latest: digest: sha256:aab56a47a320bf1c93f9632aab590a192331431425b578dffbcb0374ed4a14a7 size: 3883\n",
      "2020/06/06 19:29:50 Successfully pushed image: wfml021f814e.azurecr.io/azureml/azureml_9bd7915d3e8a44ee288f6db64640f456:latest\n",
      "2020/06/06 19:29:50 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 200.326490)\n",
      "2020/06/06 19:29:50 Populating digests for step ID: acb_step_0...\n",
      "2020/06/06 19:29:52 Successfully populated digests for step ID: acb_step_0\n",
      "2020/06/06 19:29:52 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 117.912484)\n",
      "2020/06/06 19:29:52 The following dependencies were found:\n",
      "2020/06/06 19:29:52 \n",
      "- image:\n",
      "    registry: wfml021f814e.azurecr.io\n",
      "    repository: azureml/azureml_9bd7915d3e8a44ee288f6db64640f456\n",
      "    tag: latest\n",
      "    digest: sha256:aab56a47a320bf1c93f9632aab590a192331431425b578dffbcb0374ed4a14a7\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/base\n",
      "    tag: intelmpi2018.3-ubuntu16.04\n",
      "    digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "  git: {}\n",
      "\n",
      "Run ID: cf1 was successful after 5m24s\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt\n",
      "========================================================================================================================\n",
      "2020-06-06T19:33:51Z Starting output-watcher...\n",
      "2020-06-06T19:33:51Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt\n",
      "===============================================================================================================\n",
      "Entering job preparation. Current time:2020-06-06T19:35:20.768541\n",
      "Starting job preparation. Current time:2020-06-06T19:35:21.338316\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: 581f57cd-158d-4787-b718-6c595e932921\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 57\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "downloadDataStore - Download from datastores if requested.\n",
      "Entering context manager injector. Current time:2020-06-06T19:35:24.108716\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2020/06/06 19:35:26 Starting App Insight Logger for task:  runTaskLet\n",
      "Entering context manager injector. Current time:2020-06-06T19:35:28.077821\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 119\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ train_diabetes.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/wfml/azureml/d9fe4a7a-5431-4a16-bc22-4536be69f64f/mounts/workspaceblobstore/azureml/d9fe4a7a-5431-4a16-bc22-4536be69f64f/model_folder']\n",
      "After variable expansion, calling script [ train_diabetes.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/wfml/azureml/d9fe4a7a-5431-4a16-bc22-4536be69f64f/mounts/workspaceblobstore/azureml/d9fe4a7a-5431-4a16-bc22-4536be69f64f/model_folder']\n",
      "\n",
      "Loading Data...\n",
      "/azureml-envs/azureml_7b128fbfa600b67b9d3fa44f93754ed3/lib/python3.6/site-packages/azureml/dataprep/api/dataflow.py:722: UserWarning: Your pandas and pyarrow versions are incompatible. Please install pyarrow>=0.12.0 for improved performance of to_pandas_dataframe. You can ensure the correct version is installed by running: pip install pyarrow>=0.12.0 --upgrade\n",
      "  warnings.warn('Your pandas and pyarrow versions are incompatible. '\n",
      "Training a decision tree model\n",
      "Accuracy: 0.8995555555555556\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt\n",
      "===============================================================================================================\n",
      "Entering job release. Current time:2020-06-06T19:35:50.304195\n",
      "Starting job release. Current time:2020-06-06T19:35:52.041215\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 327\n",
      "Entering context manager injector. Current time:2020-06-06T19:35:52.060172\n",
      "Job release is complete. Current time:2020-06-06T19:35:53.102262\n",
      "\n",
      "StepRun(Train Model) Execution Summary\n",
      "=======================================\n",
      "StepRun( Train Model ) Status: Finished\n",
      "{'runId': 'd9fe4a7a-5431-4a16-bc22-4536be69f64f', 'target': 'wfml-cluster', 'status': 'Completed', 'startTimeUtc': '2020-06-06T19:33:48.138084Z', 'endTimeUtc': '2020-06-06T19:36:00.18874Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '581f57cd-158d-4787-b718-6c595e932921', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'c62f9f98-43df-4188-9bf4-33d619a42546', 'azureml.pipelinerunid': 'ba5f74e1-b67f-4ff6-b063-059d3c605853', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '990099df-5f65-49cf-b19f-75cc5c987fbf'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes_train', 'mechanism': 'Direct'}}], 'runDefinition': {'script': 'train_diabetes.py', 'useAbsolutePath': False, 'arguments': ['--output_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'wfml-cluster', 'dataReferences': {'model_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/d9fe4a7a-5431-4a16-bc22-4536be69f64f/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'diabetes_train': {'dataLocation': {'dataset': {'id': '990099df-5f65-49cf-b19f-75cc5c987fbf'}, 'dataPath': None}, 'mechanism': 'Direct', 'environmentVariableName': 'diabetes_train', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment diabetes-training-pipeline Environment', 'version': 'Autosave_2020-06-06T19:24:17Z_028d3e2f', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk~=1.6.0']}, 'scikit-learn', 'pandas'], 'name': 'azureml_7b128fbfa600b67b9d3fa44f93754ed3'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'itpCompute': {'configuration': {}}, 'cmAksCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.d9fe4a7a-5431-4a16-bc22-4536be69f64f/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=JGOfT5dMH10fdMdQCaGDY95ULQne3M%2BQ%2FQert0S20KY%3D&st=2020-06-06T19%3A27%3A06Z&se=2020-06-07T03%3A37%3A06Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.d9fe4a7a-5431-4a16-bc22-4536be69f64f/azureml-logs/55_azureml-execution-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt?sv=2019-02-02&sr=b&sig=2jnj%2FJu32rqMV77WHeXdC1CCqd8gzi9aA0j%2FAv2ckMU%3D&st=2020-06-06T19%3A27%3A06Z&se=2020-06-07T03%3A37%3A06Z&sp=r', 'azureml-logs/65_job_prep-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.d9fe4a7a-5431-4a16-bc22-4536be69f64f/azureml-logs/65_job_prep-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt?sv=2019-02-02&sr=b&sig=1nOeJ5Q8M46eIji7lw0p828ktQJXivHSWShOl5rBwHs%3D&st=2020-06-06T19%3A27%3A06Z&se=2020-06-07T03%3A37%3A06Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.d9fe4a7a-5431-4a16-bc22-4536be69f64f/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=I91Dg4ebk2YccwoifbZoKdBGaPw9XFQZqZbRmDYy1GY%3D&st=2020-06-06T19%3A27%3A06Z&se=2020-06-07T03%3A37%3A06Z&sp=r', 'azureml-logs/75_job_post-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.d9fe4a7a-5431-4a16-bc22-4536be69f64f/azureml-logs/75_job_post-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt?sv=2019-02-02&sr=b&sig=05uEMqevvXCHSWH2OXiDrkguqjGf8CAUrRVdpf2dTgE%3D&st=2020-06-06T19%3A27%3A06Z&se=2020-06-07T03%3A37%3A06Z&sp=r', 'azureml-logs/process_info.json': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.d9fe4a7a-5431-4a16-bc22-4536be69f64f/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=7ZuCz%2BQwS%2BJwIMHnpRiFsxW6MiL3E20L8bG9d%2BmthFM%3D&st=2020-06-06T19%3A27%3A06Z&se=2020-06-07T03%3A37%3A06Z&sp=r', 'azureml-logs/process_status.json': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.d9fe4a7a-5431-4a16-bc22-4536be69f64f/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=heqqP1a2ZRclxzb1qCSQ36lDLQnZwGrFDL3NpDruhYA%3D&st=2020-06-06T19%3A27%3A06Z&se=2020-06-07T03%3A37%3A06Z&sp=r', 'logs/azureml/119_azureml.log': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.d9fe4a7a-5431-4a16-bc22-4536be69f64f/logs/azureml/119_azureml.log?sv=2019-02-02&sr=b&sig=9nHcsH7nLOyM3%2BQrgsYZ8lTqppbIXunBCuqpltTWmW4%3D&st=2020-06-06T19%3A27%3A06Z&se=2020-06-07T03%3A37%3A06Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.d9fe4a7a-5431-4a16-bc22-4536be69f64f/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=IbUGUKSHXCrjnjZIpM%2BLwfOdmYCqijzSpITyn6CpmuY%3D&st=2020-06-06T19%3A27%3A06Z&se=2020-06-07T03%3A37%3A06Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.d9fe4a7a-5431-4a16-bc22-4536be69f64f/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=u92RLNSKv%2B0yQ2%2BlRn5nypuzaHUWmKZ4fCUZN%2F%2B%2BEO8%3D&st=2020-06-06T19%3A27%3A06Z&se=2020-06-07T03%3A37%3A06Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.d9fe4a7a-5431-4a16-bc22-4536be69f64f/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=Kyg2rB2o0jjxDv0hnko7PIGsGXLfOChMG8v8MotoL6Q%3D&st=2020-06-06T19%3A27%3A06Z&se=2020-06-07T03%3A37%3A06Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.d9fe4a7a-5431-4a16-bc22-4536be69f64f/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=cVTcvwiGKVOoU6Rj1J5oC7C33YgV3ILsUOOSAj9kmS8%3D&st=2020-06-06T19%3A27%3A07Z&se=2020-06-07T03%3A37%3A07Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.d9fe4a7a-5431-4a16-bc22-4536be69f64f/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=LP%2BG%2F3ta%2FAqCGPjG8BgxEKPBL9p6oJ%2FKn16SssaqNVg%3D&st=2020-06-06T19%3A27%3A07Z&se=2020-06-07T03%3A37%3A07Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "StepRunId: 9a5219b4-40b2-4f0e-bf26-2fda2b86b577\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/9a5219b4-40b2-4f0e-bf26-2fda2b86b577?wsid=/subscriptions/4e5d3b1b-eba9-4974-b060-30a0ce055e02/resourcegroups/learn-4b2f634a-7e30-4f6d-b89c-3217df1e9c0f/workspaces/wfml\n",
      "StepRun( Register Model ) Status: NotStarted\n",
      "StepRun( Register Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt\n",
      "========================================================================================================================\n",
      "2020-06-06T19:37:21Z Starting output-watcher...\n",
      "2020-06-06T19:37:21Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "964bb7677f5fce8f704c5d6a32b6ea261e4d8369daadd0bd5bc366abf2fa6e9c\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt\n",
      "===============================================================================================================\n",
      "Entering job preparation. Current time:2020-06-06T19:37:23.073297\n",
      "Starting job preparation. Current time:2020-06-06T19:37:23.621735\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: 581f57cd-158d-4787-b718-6c595e932921\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 59\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "downloadDataStore - Download from datastores if requested.\n",
      "Entering context manager injector. Current time:2020-06-06T19:37:25.126914\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2020/06/06 19:37:27 Starting App Insight Logger for task:  runTaskLet\n",
      "Entering context manager injector. Current time:2020-06-06T19:37:29.147017\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 121\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ register_diabetes.py ] with arguments: ['--model_folder', '/mnt/batch/tasks/shared/LS_root/jobs/wfml/azureml/9a5219b4-40b2-4f0e-bf26-2fda2b86b577/mounts/workspaceblobstore/azureml/d9fe4a7a-5431-4a16-bc22-4536be69f64f/model_folder']\n",
      "After variable expansion, calling script [ register_diabetes.py ] with arguments: ['--model_folder', '/mnt/batch/tasks/shared/LS_root/jobs/wfml/azureml/9a5219b4-40b2-4f0e-bf26-2fda2b86b577/mounts/workspaceblobstore/azureml/d9fe4a7a-5431-4a16-bc22-4536be69f64f/model_folder']\n",
      "\n",
      "Loading model from /mnt/batch/tasks/shared/LS_root/jobs/wfml/azureml/9a5219b4-40b2-4f0e-bf26-2fda2b86b577/mounts/workspaceblobstore/azureml/d9fe4a7a-5431-4a16-bc22-4536be69f64f/model_folder\n",
      "Registering model diabetes_model\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 121\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.12916970252990723 seconds\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt\n",
      "===============================================================================================================\n",
      "Entering job release. Current time:2020-06-06T19:37:36.162349\n",
      "Starting job release. Current time:2020-06-06T19:37:37.895413\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 159\n",
      "Entering context manager injector. Current time:2020-06-06T19:37:37.914001\n",
      "Job release is complete. Current time:2020-06-06T19:37:40.954484\n",
      "\n",
      "StepRun(Register Model) Execution Summary\n",
      "==========================================\n",
      "StepRun( Register Model ) Status: Finished\n",
      "{'runId': '9a5219b4-40b2-4f0e-bf26-2fda2b86b577', 'target': 'wfml-cluster', 'status': 'Completed', 'startTimeUtc': '2020-06-06T19:37:20.947448Z', 'endTimeUtc': '2020-06-06T19:37:43.354132Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '581f57cd-158d-4787-b718-6c595e932921', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'd2b46840-f147-484b-993d-a1d5e736abf5', 'azureml.pipelinerunid': 'ba5f74e1-b67f-4ff6-b063-059d3c605853', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'runDefinition': {'script': 'register_diabetes.py', 'useAbsolutePath': False, 'arguments': ['--model_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'wfml-cluster', 'dataReferences': {'model_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/d9fe4a7a-5431-4a16-bc22-4536be69f64f/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment diabetes-training-pipeline Environment', 'version': 'Autosave_2020-06-06T19:24:17Z_028d3e2f', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk~=1.6.0']}, 'scikit-learn', 'pandas'], 'name': 'azureml_7b128fbfa600b67b9d3fa44f93754ed3'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'itpCompute': {'configuration': {}}, 'cmAksCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.9a5219b4-40b2-4f0e-bf26-2fda2b86b577/azureml-logs/55_azureml-execution-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt?sv=2019-02-02&sr=b&sig=geLuLAEIVr4aCY%2FBbloit%2F3HbHaHTg75FQG%2FWwUroAU%3D&st=2020-06-06T19%3A27%3A46Z&se=2020-06-07T03%3A37%3A46Z&sp=r', 'azureml-logs/65_job_prep-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.9a5219b4-40b2-4f0e-bf26-2fda2b86b577/azureml-logs/65_job_prep-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt?sv=2019-02-02&sr=b&sig=SMhh1%2BV6Ij3j1r82uODDETrnGPNXLpRajwU3zSBDRV8%3D&st=2020-06-06T19%3A27%3A46Z&se=2020-06-07T03%3A37%3A46Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.9a5219b4-40b2-4f0e-bf26-2fda2b86b577/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=WjZ1NJAtYlBdpdr904LmfCT96mKqudBEDC5%2By82c6eM%3D&st=2020-06-06T19%3A27%3A46Z&se=2020-06-07T03%3A37%3A46Z&sp=r', 'azureml-logs/75_job_post-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.9a5219b4-40b2-4f0e-bf26-2fda2b86b577/azureml-logs/75_job_post-tvmps_229a8617a062606b14c815497d564113c940eaacd406ec7f9a9461524b57f68a_d.txt?sv=2019-02-02&sr=b&sig=KgM%2BIDWfYupzGvLoutKItU%2BSWQOH6IjnWoOxFgsaiOA%3D&st=2020-06-06T19%3A27%3A46Z&se=2020-06-07T03%3A37%3A46Z&sp=r', 'azureml-logs/process_info.json': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.9a5219b4-40b2-4f0e-bf26-2fda2b86b577/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=DS49nRh%2Bz4T0q8nIsIRBBHLpf%2Bc9YpoEhSSeGr%2Foijc%3D&st=2020-06-06T19%3A27%3A46Z&se=2020-06-07T03%3A37%3A46Z&sp=r', 'azureml-logs/process_status.json': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.9a5219b4-40b2-4f0e-bf26-2fda2b86b577/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=C2W%2Fhh8Dna6Neeq6L8MeeMUVVde3ZCyCtvTto957Huc%3D&st=2020-06-06T19%3A27%3A47Z&se=2020-06-07T03%3A37%3A47Z&sp=r', 'logs/azureml/121_azureml.log': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.9a5219b4-40b2-4f0e-bf26-2fda2b86b577/logs/azureml/121_azureml.log?sv=2019-02-02&sr=b&sig=H5531LeS9FEHcMLN%2FW1Ql3j%2B8cCeUhViWgFr%2F9Fdul0%3D&st=2020-06-06T19%3A27%3A46Z&se=2020-06-07T03%3A37%3A46Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.9a5219b4-40b2-4f0e-bf26-2fda2b86b577/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=A63VOzXKNU2sB7TRSBNe9GvO%2BhAFVVIweHo5dQ%2F2RNE%3D&st=2020-06-06T19%3A27%3A46Z&se=2020-06-07T03%3A37%3A46Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.9a5219b4-40b2-4f0e-bf26-2fda2b86b577/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=gbOwqSmv5K3mfQyknRpbYa%2BT9N41NlAzMLG7QI0t1Qg%3D&st=2020-06-06T19%3A27%3A46Z&se=2020-06-07T03%3A37%3A46Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.9a5219b4-40b2-4f0e-bf26-2fda2b86b577/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=4ws8Ruh%2F3xI7Juaef9Hkun9JVAddMqoQQrTTMVlzNlY%3D&st=2020-06-06T19%3A27%3A46Z&se=2020-06-07T03%3A37%3A46Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.9a5219b4-40b2-4f0e-bf26-2fda2b86b577/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=bS1rbMhOXZ4PSR9IRlfUdcErxdKAhaGLs67tlJYRvFA%3D&st=2020-06-06T19%3A27%3A46Z&se=2020-06-07T03%3A37%3A46Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.9a5219b4-40b2-4f0e-bf26-2fda2b86b577/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=6xicTLrNhlldTRKhvxLOBM3ifUfmscGpcmdmf61t%2BsI%3D&st=2020-06-06T19%3A27%3A46Z&se=2020-06-07T03%3A37%3A46Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'ba5f74e1-b67f-4ff6-b063-059d3c605853', 'status': 'Completed', 'startTimeUtc': '2020-06-06T19:24:07.26121Z', 'endTimeUtc': '2020-06-06T19:37:45.695654Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.ba5f74e1-b67f-4ff6-b063-059d3c605853/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=le%2Bn49nTe6RMQk3GM6xHeFxkiyoILQU5gMsedzAt3gI%3D&st=2020-06-06T19%3A27%3A48Z&se=2020-06-07T03%3A37%3A48Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.ba5f74e1-b67f-4ff6-b063-059d3c605853/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=7zRv26sQ4Iz5qDFPomyVFguNazBK%2FsZqoMuQ3fs35fA%3D&st=2020-06-06T19%3A27%3A48Z&se=2020-06-07T03%3A37%3A48Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://wfml9304001958.blob.core.windows.net/azureml/ExperimentRun/dcid.ba5f74e1-b67f-4ff6-b063-059d3c605853/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=jER9nKCIyHxZLbcJhCQjfY93zRmNaOLc08oJv%2BdqC0g%3D&st=2020-06-06T19%3A27%3A48Z&se=2020-06-07T03%3A37%3A48Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [train_step, register_step]\n",
    "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace = ws, name = 'diabetes-training-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The widget above shows details of the pipeline as it runs. You can also monitor pipeline runs in the **Experiments** page in [Azure Machine Learning studio](https://ml.azure.com).\n",
    "\n",
    "When the pipeline has finished, a new model should be registered with a *Training context* tag indicating it was trained in a pipeline. Run the following code to verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version: 1\n",
      "\t Training context : Pipeline\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the Pipeline\n",
    "\n",
    "Now that you've created a pipeline and verified it works, you can publish it as a REST service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://westus.api.azureml.ms/pipelines/v1.0/subscriptions/4e5d3b1b-eba9-4974-b060-30a0ce055e02/resourceGroups/learn-4b2f634a-7e30-4f6d-b89c-3217df1e9c0f/providers/Microsoft.MachineLearningServices/workspaces/wfml/PipelineRuns/PipelineSubmit/c1661037-c503-46ca-88ce-aded4b60c4fb\n"
     ]
    }
   ],
   "source": [
    "published_pipeline = pipeline.publish(name=\"Diabetes_Training_Pipeline\",\n",
    "                                      description=\"Trains diabetes model\",\n",
    "                                      version=\"1.0\")\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. A real application would require a service principal with which to be authenticated, but to test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to call the REST interface. The pipeline runs asynchronously, so you'll get an identifier back, which you can use to track the pipeline experiment as it runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5c0c9db5-2473-4f00-acac-b2fb9c3893b6'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "experiment_name = 'Run-diabetes-pipeline'\n",
    "\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Error': {'Code': 'InternalServerError',\n",
       "  'Message': 'The operation was canceled.',\n",
       "  'MessageFormat': None,\n",
       "  'MessageParameters': None,\n",
       "  'ReferenceCode': None,\n",
       "  'DetailsUri': None,\n",
       "  'Target': None,\n",
       "  'Details': [],\n",
       "  'InnerError': None,\n",
       "  'DebugInfo': None},\n",
       " 'Correlation': {'operation': 'cc91dfd0d32e5c4ba84bded35de9b416',\n",
       "  'request': 'ceb044eb860cde50'},\n",
       " 'Environment': 'westus',\n",
       " 'Location': 'westus',\n",
       " 'Time': '2020-06-06T19:41:18.5277497+00:00'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Debug KeyError with Id\n",
    "run_id_test = response.json()\n",
    "run_id_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you have the run ID, you can use the **RunDetails** widget to view the experiment as it runs.\n",
    "\n",
    "> **Note**: The pipeline should complete quickly, because each step was configured to allow output reuse. This was done primarily for convenience and to save time in this example. In reality, you'd likely want the first step to run every time in case the data has changed, and trigger the subsequent steps only if the output from step one changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4375d87cab254bbf81beb8c959a27710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"loading\": true}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
    "RunDetails(published_pipeline_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example, designed to demonstrate the principle. In reality, you could build more sophisticated logic into the pipeline steps - for example, evaluating the model against some test data to calculate a performance metric like AUC or accuracy, comparing the metric to that of any previously registered versions of the model, and only registering the new model if it performs better.\n",
    "\n",
    "You can use the [Azure Machine Learning extension for Azure DevOps](https://marketplace.visualstudio.com/items?itemName=ms-air-aiagility.vss-services-azureml) to combine Azure ML pipelines with Azure DevOps pipelines (yes, it *is* confusing that they have the same name!) and integrate model retraining into a *continuous integration/continuous deployment (CI/CD)* process. For example you could use an Azure DevOps *build* pipeline to trigger an Azure ML pipeline that trains and registers a model, and when the model is registered it could trigger an Azure Devops *release* pipeline that deploys the model as a web service, along with the application or service that consumes the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
